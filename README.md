## Model
LLM for fairy tales extraction: mistral-7b-instruct-v0.1.Q4_0. [doc](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF) <br/>
Named Entity Recognition (NER) model for identify character: gliner_mediumv2.1. [doc](https://huggingface.co/urchade/gliner_medium-v2.1)<br/>
Text to speech: xtts_v2. [doc](https://huggingface.co/coqui/XTTS-v2) & [paper](https://arxiv.org/pdf/2406.04904)<br/>
Emotion classifier: DistilRoBERTa-base. [doc](https://huggingface.co/michellejieli/emotion_text_classifier)<br/>
Music generate: MusicGen. [doc](https://huggingface.co/facebook/musicgen-small) & [paper](https://arxiv.org/abs/2306.05284)
Image generate: Text-to-Image. [doc](https://huggingface.co/ZB-Tech/Text-to-Image)

## Folder
Model for LLM: Put [mistral-7b-instruct](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF) model in the **Model** folder<br/>
Story: Install fairy tales from [here](https://drive.google.com/drive/u/0/folders/1GVB8rZhbVewnPd2CNA5tshupF01z0DtD) and put it in **fairy_tales** folder<br/>
Voice: [These](https://drive.google.com/drive/u/0/folders/1GVB8rZhbVewnPd2CNA5tshupF01z0DtD) are example voice for the text to speech

## Contributors & Collaborators

<table>
  <tbody>
      <td align="center" valign="top" width="14.28%"><a href="https://github.com/EricHuaaa"><img src="https://avatars.githubusercontent.com/u/91867104?v=4" width="100px;" alt="黃紹綱"/><br /><sub><b>黃紹綱</b></sub></a>
  </tbody>
</table>