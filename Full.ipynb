{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f53f4a",
   "metadata": {},
   "source": [
    "### ÈåÑÈü≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac3d750-ee19-4b21-880f-098e482285a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "c:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from TTS.api import TTS\n",
    "from gliner import GLiNER\n",
    "from diffusers import DiffusionPipeline\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from utils import *\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c80161f1-3c3e-4173-b39f-7e52505aa63c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<?, ?it/s]\n",
      "c:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\TTS\\tts\\layers\\xtts\\xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.speakers = torch.load(speaker_file_path)\n",
      "c:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\TTS\\utils\\io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "gn = GLiNER.from_pretrained(\"urchade/gliner_mediumv2.1\").to(device)\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"michellejieli/emotion_text_classifier\",  device=device)\n",
    "# pipeline = DiffusionPipeline.from_pretrained(\"stable-diffusion-v1-5/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f3dd63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wolf-Wind</td>\n",
       "      <td>I am Wolf-Wind, the giant,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wolf-Wind</td>\n",
       "      <td>cross not my path, for I will kill all the peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wolf-Wind</td>\n",
       "      <td>I will catch you and kill you all and eat you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>I will come back and catch you yet. You cannot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>You cannot harm us; we are strong, for we came...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     speaker                                            content\n",
       "0  Wolf-Wind                         I am Wolf-Wind, the giant,\n",
       "1  Wolf-Wind  cross not my path, for I will kill all the peo...\n",
       "2  Wolf-Wind  I will catch you and kill you all and eat you ...\n",
       "3    Unknown  I will come back and catch you yet. You cannot...\n",
       "4    Unknown  You cannot harm us; we are strong, for we came..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./output_char/output_25.json', 'r') as file:\n",
    "    result = json.load(file)\n",
    "    \n",
    "quotes_data = []\n",
    "for entry in result:\n",
    "    for quote in entry['quotes']:\n",
    "        quotes_data.append({\n",
    "            \"speaker\": quote['speaker']['name'],\n",
    "            \"content\": quote['quote']\n",
    "        })\n",
    "df = pd.DataFrame(quotes_data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83cc29",
   "metadata": {},
   "source": [
    "### (NER) model for identify character & Emotion classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb756163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "df['content'] = df['content'].str.replace('\\n', ' ', regex=False)\n",
    "\n",
    "df['emotion'] = None\n",
    "df['char'] = None\n",
    "\n",
    "labels = [\"Male\", \"Female\", \"Other\"]\n",
    "\n",
    "# Áç≤ÂèñÊÉÖÁ∑íÂíåËßíËâ≤Ë∫´ÂàÜ\n",
    "for c in range(df.shape[0]):\n",
    "    sentence_with_name = f\"{df['speaker'][c]} : {df['content'][c]}\"\n",
    "    sentence_only = df['content'][c]\n",
    "    \n",
    "    classify_result = classifier(sentence_only)\n",
    "    gn_result = gn.predict_entities(sentence_with_name, labels, threshold=0.2)# thresholdÈÅéÈ´òÁÑ°Ê≥ïÂà§Êñ∑\n",
    "    \n",
    "    df.loc[c, 'emotion'] = classify_result[0]['label'] \n",
    "    df.loc[c, 'char'] = gn_result[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e36b0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./fairy_tales/69.txt\", 'r',  encoding='utf-8') as file:\n",
    "    content = \" \".join(file.read().split())\n",
    "\n",
    "cleaned_content = re.sub(r\"\\\\'\", \"'\", content)\n",
    "\n",
    "##---ÂÜç‰æÜËÆÄquote_analysis_result.json ËÆäÊàêdf(‰∏çËÆä) ->ÂéüÊú¨‰Ω†ÂØ´ÁöÑ---##\n",
    "\n",
    "dialogue_count = 0\n",
    "dialogues = []\n",
    "lines = cleaned_content.split('\"')\n",
    "# print(lines)\n",
    "\n",
    "lines = [line for line in lines if line.strip()]\n",
    "ori = pd.DataFrame(lines, columns=['content'])\n",
    "merged = ori.merge(df, \n",
    "                  left_on='content', \n",
    "                  right_on='content', \n",
    "                  how='left')\n",
    "merged['speaker'] = merged['char'].fillna('Other')\n",
    "merged['speaker'] = merged['emotion'].fillna('neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca4b839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>content</th>\n",
       "      <th>emotion</th>\n",
       "      <th>char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wolf-Wind</td>\n",
       "      <td>I am Wolf-Wind, the giant,</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wolf-Wind</td>\n",
       "      <td>cross not my path, for I will kill all the peo...</td>\n",
       "      <td>anger</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wolf-Wind</td>\n",
       "      <td>I will catch you and kill you all and eat you ...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>I will come back and catch you yet. You cannot...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>You cannot harm us; we are strong, for we came...</td>\n",
       "      <td>fear</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wolf-Wind</td>\n",
       "      <td>Now I have overcome the leaves that kept me aw...</td>\n",
       "      <td>anger</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Glooskap</td>\n",
       "      <td>What do you wish?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the children</td>\n",
       "      <td>We wish nothing for ourselves,</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the children</td>\n",
       "      <td>but we ask that the leaves that were killed by...</td>\n",
       "      <td>anger</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Wolf</td>\n",
       "      <td>I cannot bring back to the trees the leaves th...</td>\n",
       "      <td>joy</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker                                            content  emotion  \\\n",
       "0     Wolf-Wind                         I am Wolf-Wind, the giant,  neutral   \n",
       "1     Wolf-Wind  cross not my path, for I will kill all the peo...    anger   \n",
       "2     Wolf-Wind  I will catch you and kill you all and eat you ...  disgust   \n",
       "3       Unknown  I will come back and catch you yet. You cannot...  neutral   \n",
       "4       Unknown  You cannot harm us; we are strong, for we came...     fear   \n",
       "5     Wolf-Wind  Now I have overcome the leaves that kept me aw...    anger   \n",
       "6      Glooskap                                  What do you wish?  neutral   \n",
       "7  the children                     We wish nothing for ourselves,  sadness   \n",
       "8  the children  but we ask that the leaves that were killed by...    anger   \n",
       "9      The Wolf  I cannot bring back to the trees the leaves th...      joy   \n",
       "\n",
       "     char  \n",
       "0    Male  \n",
       "1    Male  \n",
       "2   Other  \n",
       "3   Other  \n",
       "4   Other  \n",
       "5    Male  \n",
       "6   Other  \n",
       "7   Other  \n",
       "8  Female  \n",
       "9    Male  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b66e08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>speaker</th>\n",
       "      <th>emotion</th>\n",
       "      <th>char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAIR, BROWN, AND TREMBLING King Hugh Curucha l...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's at church you ought to be this day, inste...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How could I go?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said Trembling.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have no clothes good enough to wear at churc...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>As soon as the cowboy came home, the eldest s...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>If the little girl that is born to us now live...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>The cowboy and the prince's daughter lived on...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>You could not have saved me from the whale but...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>The son of the king of Emania and Trembling h...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  speaker emotion char\n",
       "0    FAIR, BROWN, AND TREMBLING King Hugh Curucha l...  neutral     NaN  NaN\n",
       "1    It's at church you ought to be this day, inste...  neutral     NaN  NaN\n",
       "2                                      How could I go?  neutral     NaN  NaN\n",
       "3                                     said Trembling.   neutral     NaN  NaN\n",
       "4    I have no clothes good enough to wear at churc...  neutral     NaN  NaN\n",
       "..                                                 ...      ...     ...  ...\n",
       "104   As soon as the cowboy came home, the eldest s...  neutral     NaN  NaN\n",
       "105  If the little girl that is born to us now live...  neutral     NaN  NaN\n",
       "106   The cowboy and the prince's daughter lived on...  neutral     NaN  NaN\n",
       "107  You could not have saved me from the whale but...  neutral     NaN  NaN\n",
       "108   The son of the king of Emania and Trembling h...  neutral     NaN  NaN\n",
       "\n",
       "[109 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f578feb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>content</th>\n",
       "      <th>emotion</th>\n",
       "      <th>char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wolf-Wind</td>\n",
       "      <td>I am Wolf-Wind, the giant,</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wolf-Wind</td>\n",
       "      <td>cross not my path, for I will kill all the peo...</td>\n",
       "      <td>anger</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wolf-Wind</td>\n",
       "      <td>I will catch you and kill you all and eat you ...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>I will come back and catch you yet. You cannot...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>You cannot harm us; we are strong, for we came...</td>\n",
       "      <td>fear</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     speaker                                            content  emotion  \\\n",
       "0  Wolf-Wind                         I am Wolf-Wind, the giant,  neutral   \n",
       "1  Wolf-Wind  cross not my path, for I will kill all the peo...    anger   \n",
       "2  Wolf-Wind  I will catch you and kill you all and eat you ...  disgust   \n",
       "3    Unknown  I will come back and catch you yet. You cannot...  neutral   \n",
       "4    Unknown  You cannot harm us; we are strong, for we came...     fear   \n",
       "\n",
       "    char  \n",
       "0   Male  \n",
       "1   Male  \n",
       "2  Other  \n",
       "3  Other  \n",
       "4  Other  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d9ff70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40f1d86",
   "metadata": {},
   "source": [
    "## Êö´ÊôÇÂéªÊéâLLMÂÖßÂÆπ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7d15ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = llm(content)\n",
    "\n",
    "# df = pd.DataFrame(result)\n",
    "# df['emotion'] = None\n",
    "# df['char'] = None\n",
    "\n",
    "# labels = [\"Male\", \"Female\", \"Other\"]\n",
    "\n",
    "# # Áç≤ÂèñÊÉÖÁ∑íÂíåËßíËâ≤Ë∫´ÂàÜ\n",
    "# for c in range(df.shape[0]):\n",
    "#     sentence_with_name = f\"{df['speaker'][c]} : {df['content'][c]}\"\n",
    "#     sentence_only = df['content'][c]\n",
    "    \n",
    "#     classify_result = classifier(sentence_only)\n",
    "#     gn_result = gn.predict_entities(sentence_with_name, labels, threshold=0.2)# thresholdÈÅéÈ´òÁÑ°Ê≥ïÂà§Êñ∑\n",
    "    \n",
    "#     df.loc[c, 'emotion'] = classify_result[0]['label'] \n",
    "#     df.loc[c, 'char'] = gn_result[0]['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980326ff",
   "metadata": {},
   "source": [
    "## Image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27afb646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using torch < 2.0\n",
    "# pipe.enable_xformers_memory_efficient_attention()\n",
    "\n",
    "prompt = \"An astronaut riding a green horse\"\n",
    "\n",
    "images = pipe(prompt=prompt).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccdb59f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me a picture represent the following content: It's at church you ought to be this day, instead of working here at home. How could I go?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [02:42<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as Images/output_image_0.png\n",
      "Give me a picture represent the following content: I have no clothes good enough to wear at church; and if my sisters were to see me there, they'd kill me for going out of the house. I'll give you,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 2/50 [00:10<04:23,  5.50s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGive me a picture represent the following content:\u001b[39m\u001b[38;5;124m'\u001b[39m,combined_content)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Generate image using the pipeline\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_content\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Save the generated image\u001b[39;00m\n\u001b[0;32m     19\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImages/output_image_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Update batch index calculation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\diffusers\\pipelines\\stable_diffusion\\pipeline_stable_diffusion.py:1020\u001b[0m, in \u001b[0;36mStableDiffusionPipeline.__call__\u001b[1;34m(self, prompt, height, width, num_inference_steps, timesteps, sigmas, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, guidance_rescale, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1017\u001b[0m latent_model_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mscale_model_input(latent_model_input, t)\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;66;03m# predict the noise residual\u001b[39;00m\n\u001b[1;32m-> 1020\u001b[0m noise_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_model_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestep_cond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestep_cond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;66;03m# perform guidance\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_classifier_free_guidance:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\diffusers\\models\\unets\\unet_2d_condition.py:1281\u001b[0m, in \u001b[0;36mUNet2DConditionModel.forward\u001b[1;34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, down_intrablock_additional_residuals, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     upsample_size \u001b[38;5;241m=\u001b[39m down_block_res_samples[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(upsample_block, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_cross_attention\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m upsample_block\u001b[38;5;241m.\u001b[39mhas_cross_attention:\n\u001b[1;32m-> 1281\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[43mupsample_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mres_hidden_states_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupsample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupsample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1292\u001b[0m     sample \u001b[38;5;241m=\u001b[39m upsample_block(\n\u001b[0;32m   1293\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39msample,\n\u001b[0;32m   1294\u001b[0m         temb\u001b[38;5;241m=\u001b[39memb,\n\u001b[0;32m   1295\u001b[0m         res_hidden_states_tuple\u001b[38;5;241m=\u001b[39mres_samples,\n\u001b[0;32m   1296\u001b[0m         upsample_size\u001b[38;5;241m=\u001b[39mupsample_size,\n\u001b[0;32m   1297\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\diffusers\\models\\unets\\unet_2d_blocks.py:2551\u001b[0m, in \u001b[0;36mCrossAttnUpBlock2D.forward\u001b[1;34m(self, hidden_states, res_hidden_states_tuple, temb, encoder_hidden_states, cross_attention_kwargs, upsample_size, attention_mask, encoder_attention_mask)\u001b[0m\n\u001b[0;32m   2549\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2550\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m resnet(hidden_states, temb)\n\u001b[1;32m-> 2551\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2552\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2553\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2555\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2556\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2557\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2558\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2561\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m upsampler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\diffusers\\models\\transformers\\transformer_2d.py:442\u001b[0m, in \u001b[0;36mTransformer2DModel.forward\u001b[1;34m(self, hidden_states, encoder_hidden_states, timestep, added_cond_kwargs, class_labels, cross_attention_kwargs, attention_mask, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[0;32m    430\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    431\u001b[0m             create_custom_forward(block),\n\u001b[0;32m    432\u001b[0m             hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mckpt_kwargs,\n\u001b[0;32m    440\u001b[0m         )\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# 3. Output\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_input_continuous:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\diffusers\\models\\attention.py:488\u001b[0m, in \u001b[0;36mBasicTransformerBlock.forward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, timestep, cross_attention_kwargs, class_labels, added_cond_kwargs)\u001b[0m\n\u001b[0;32m    484\u001b[0m     norm_hidden_states, gate_msa, shift_mlp, scale_mlp, gate_mlp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[0;32m    485\u001b[0m         hidden_states, timestep, class_labels, hidden_dtype\u001b[38;5;241m=\u001b[39mhidden_states\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    486\u001b[0m     )\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_norm_i2vgen\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 488\u001b[0m     norm_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mada_norm_continuous\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    490\u001b[0m     norm_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(hidden_states, added_cond_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpooled_text_emb\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\torch\\nn\\modules\\normalization.py:217\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\graduateP\\lib\\site-packages\\torch\\nn\\functional.py:2900\u001b[0m, in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m   2891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2892\u001b[0m         layer_norm,\n\u001b[0;32m   2893\u001b[0m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2898\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m   2899\u001b[0m     )\n\u001b[1;32m-> 2900\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2901\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2902\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import io\n",
    "import time\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/ZB-Tech/Text-to-Image\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    try:\n",
    "        image_bytes = response.content\n",
    "        response.close()\n",
    "        return image_bytes\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists('Images'):\n",
    "    os.makedirs('Images')\n",
    "\n",
    "# Processing loop\n",
    "for index in range(0, len(df['content']), 5):\n",
    "    batch = df['content'][index:index+5]  # Get up to 5 entries at a time\n",
    "    combined_content = \" \".join(batch)  # Combine all batch sentences into one string\n",
    "\n",
    "    image_bytes = query({\"inputs\": combined_content})\n",
    "    if image_bytes:\n",
    "        try:\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            filename = f\"Images/output_image_{index//5}.png\"  # Save file with batch index\n",
    "            image.save(filename)\n",
    "            print(f\"Image saved as {filename}\")\n",
    "        except UnidentifiedImageError as e:\n",
    "            print(f\"Error processing image batch {index//5}: {e}\")\n",
    "\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ffc6c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "[\"It's at church you ought to be this day, instead of working here at home.\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 4.591921329498291\n",
      " > Real-time factor: 0.7337091689524443\n",
      " > Text splitted to sentences.\n",
      "['How could I go?']\n",
      " > Processing time: 0.6973443031311035\n",
      " > Real-time factor: 0.4618104842636002\n",
      " > Text splitted to sentences.\n",
      "[\"I have no clothes good enough to wear at church; and if my sisters were to see me there, they'd kill me for going out of the house.\"]\n",
      " > Processing time: 7.935988664627075\n",
      " > Real-time factor: 0.4985542407092669\n",
      " > Text splitted to sentences.\n",
      "[\"I'll give you,\"]\n",
      " > Processing time: 1.3563709259033203\n",
      " > Real-time factor: 0.46348839133660136\n",
      " > Text splitted to sentences.\n",
      "['a finer dress than either of them has ever seen.', 'And now tell me what dress will you have?']\n",
      " > Processing time: 5.202718019485474\n",
      " > Real-time factor: 0.47514882508968975\n",
      " > Text splitted to sentences.\n",
      "[\"I'll have,\"]\n",
      " > Processing time: 0.7444465160369873\n",
      " > Real-time factor: 0.4360137504944637\n",
      " > Text splitted to sentences.\n",
      "['a dress as white as snow, and green shoes for my feet.']\n",
      " > Processing time: 2.680044174194336\n",
      " > Real-time factor: 0.47394275344046827\n",
      " > Text splitted to sentences.\n",
      "['I have a honey-bird here to sit on your right shoulder, and a honey-finger to put on your left.', 'At the door stands a milk-white mare, with a golden saddle for you to sit on, and a golden bridle to hold in your hand.']\n",
      " > Processing time: 13.520735740661621\n",
      " > Real-time factor: 0.48663525574821875\n",
      " > Text splitted to sentences.\n",
      "['You must not go inside the door of the church, and the minute the people rise up at the end of Mass, do you make off, and ride home as fast as the mare will carry you.']\n",
      " > Processing time: 8.604116678237915\n",
      " > Real-time factor: 0.48658329423433977\n",
      " > Text splitted to sentences.\n",
      "['Have you any news to-day from the church?']\n",
      " > Processing time: 1.389284610748291\n",
      " > Real-time factor: 0.45836912956367937\n"
     ]
    }
   ],
   "source": [
    "speaker_mapping = {\n",
    "    'Female': \"Voice/03-01-01-01-01-01-06.wav\",\n",
    "    'Male': \"Voice/03-01-01-01-01-01-05.wav\",\n",
    "    'Other': \"Voice/03-01-01-01-01-01-11.wav\"\n",
    "}\n",
    "# default_speaker = \"Voice/03-01-01-01-01-01-11.wav\"\n",
    "default_speaker = \"Voice/3i2a1-5ax7q.wav\"\n",
    "\n",
    "# ÊñáÂ≠óÂà∞Ë™ûÈü≥\n",
    "for d in range(df.shape[0]):\n",
    "    speaker_wav = speaker_mapping.get(df['char'][d], default_speaker)\n",
    "\n",
    "    tts.tts_to_file(\n",
    "        text=df['content'][d],\n",
    "        speaker_wav=default_speaker,\n",
    "        # speaker_wav='Voice/03-01-01-01-01-01-06.wav',\n",
    "        language=\"en\",\n",
    "        emotion=df['emotion'][d],\n",
    "        file_path=f\"Results/output{d}.wav\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72ce5278-de7f-49c9-a739-bd76c0561502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='Results/combined_audio.wav'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_files = [f\"Results/output{i}.wav\" for i in range(df.shape[0])]\n",
    "\n",
    "combined_audio = AudioSegment.from_wav(wav_files[0])\n",
    "\n",
    "# ÈÄêÊ≠•Â∞áÂâ©‰∏ãÁöÑÈü≥È†ªÊñá‰ª∂Âêà‰ΩµÂà∞Á¨¨‰∏ÄÂÄãÈü≥È†ªÊñá‰ª∂‰∏≠\n",
    "for wav_file in wav_files[1:]:\n",
    "    next_audio = AudioSegment.from_wav(wav_file)\n",
    "    combined_audio += next_audio\n",
    "\n",
    "combined_audio.export(\"Results/combined_audio.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f777f6",
   "metadata": {},
   "source": [
    "## Movie and Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60a7b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import AudioFileClip, concatenate_videoclips, concatenate_audioclips, CompositeVideoClip, CompositeAudioClip, vfx\n",
    "from moviepy import ImageClip, TextClip, VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c86653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's at church you ought to be this day, instead of working here at home.\n",
      "How could I go?\n",
      "I have no clothes good enough to wear at church; and if my sisters were to see me there, they'd kill me for going out of the house.\n",
      "I'll give you,\n",
      "a finer dress than either of them has ever seen. And now tell me what dress will you have?\n",
      "I'll have,\n",
      "a dress as white as snow, and green shoes for my feet.\n",
      "I have a honey-bird here to sit on your right shoulder, and a honey-finger to put on your left. At the door stands a milk-white mare, with a golden saddle for you to sit on, and a golden bridle to hold in your hand.\n",
      "You must not go inside the door of the church, and the minute the people rise up at the end of Mass, do you make off, and ride home as fast as the mare will carry you.\n",
      "Have you any news to-day from the church?\n"
     ]
    }
   ],
   "source": [
    "output_video = \"Video/final_video2.mp4\"\n",
    "\n",
    "background_music_path = \"Music/converted_musicgen_out.wav\"\n",
    "background_music = AudioFileClip(background_music_path).with_volume_scaled(0.5)\n",
    "\n",
    "video_clips = []\n",
    "\n",
    "for index in range(0, len(df), 5):\n",
    "    image_path = f\"Images/output_image_{index//5}.png\"\n",
    "    image = ImageClip(image_path)\n",
    "\n",
    "    audios = []\n",
    "    for i in range(5):\n",
    "        if index + i < len(df):\n",
    "            audio_path = f\"Results/output{index+i}.wav\"\n",
    "            audio_clip = AudioFileClip(audio_path)\n",
    "            audios.append(audio_clip)\n",
    "\n",
    "    if audios:\n",
    "        combined_audio = concatenate_audioclips(audios)\n",
    "        image = image.with_duration(combined_audio.duration)\n",
    "\n",
    "        text_clips = []\n",
    "        current_time = 0\n",
    "        sentence_duration = combined_audio.duration / len(audios)\n",
    "        full_scroll_duration = sentence_duration + 20\n",
    "        for i, sentence in enumerate(df.loc[index:index+4, 'content']):\n",
    "            print(sentence)\n",
    "            txt_clip = TextClip(text=sentence, font_size=24, \n",
    "                                font='C:/Windows/Fonts/arial.ttf', color='white', \n",
    "                                size=(image.size[0], None), method='caption')\n",
    "            \n",
    "            start_y = image.size[1] + i * 100 \n",
    "            txt_clip = txt_clip.with_position(lambda t, start=current_time, start_y=start_y: (0, start_y - 30 * t)) # 30 ÈÄüÂ∫¶\n",
    "            txt_clip = txt_clip.with_duration(full_scroll_duration).with_start(current_time)\n",
    "            text_clips.append(txt_clip)\n",
    "            current_time += sentence_duration * 0.3 # ÊñáÂ≠óÂá∫ÁèæÁöÑÊôÇÈñì\n",
    "            \n",
    "        video = CompositeVideoClip([image] + text_clips).with_audio(combined_audio)\n",
    "        video_clips.append(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd58f2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂΩ±ÁâáÁîüÊàêÊàêÂäüÔºöVideo/final_video2.mp4\n"
     ]
    }
   ],
   "source": [
    "# Âêà‰ΩµÊâÄÊúâÁâáÊÆµ\n",
    "final_video = concatenate_videoclips(video_clips)\n",
    "\n",
    "loops = int(final_video.duration // background_music.duration) + 1\n",
    "\n",
    "# background_music.with_duration(final_video.duration)\n",
    "full_music = concatenate_audioclips([background_music] * loops)\n",
    "\n",
    "final_audio = CompositeAudioClip([final_video.audio, full_music])\n",
    "\n",
    "# Ë®≠ÁΩÆÊ∑∑ÂêàÂæåÁöÑÈü≥È†ªÁÇ∫ÂΩ±ÁâáÁöÑÈü≥È†ªËªåÈÅì\n",
    "final_video = final_video.with_audio(final_audio)\n",
    "final_video.write_videofile(\n",
    "    output_video,\n",
    "    codec=\"libx264\",\n",
    "    audio_codec=\"aac\",\n",
    "    temp_audiofile=\"temp-audio.m4a\",\n",
    "    remove_temp=True,\n",
    "    fps=24,\n",
    "    threads=4,\n",
    "    logger=None\n",
    ")\n",
    "\n",
    "print(f\"ÂΩ±ÁâáÁîüÊàêÊàêÂäüÔºö{output_video}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graduateP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
