{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hoisaline\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"michellejieli/emotion_text_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How could I go?',\n",
       " \"I'll give you,\",\n",
       " \"I'll have,\",\n",
       " 'We have great news,',\n",
       " 'I would go,',\n",
       " 'if I could get the going.',\n",
       " 'What robe will you wear?',\n",
       " 'The finest black satin that can be found, and red shoes for my feet.',\n",
       " 'What colour do you want the mare to be?',\n",
       " 'What news have you to-day?',\n",
       " 'Well, my dear, are you for church to-day?',\n",
       " 'I would go if I had a new dress to wear.',\n",
       " \"I'll get you any dress you ask for. What dress would you like?\",\n",
       " \"What's the trouble that's on you now?\",\n",
       " \"Don't mind that; don't be vexed,\",\n",
       " 'Have you any news from the church?',\n",
       " 'We have indeed,',\n",
       " 'Well,',\n",
       " \"Maybe it's my foot that the shoe will fit.\",\n",
       " 'Is there any other young woman in the house?',\n",
       " 'There is,',\n",
       " \"I'm here.\",\n",
       " 'Oh! we have her for nothing but to put out the ashes,',\n",
       " 'Do you stay here till I return.',\n",
       " 'This is the lady we saw at church.',\n",
       " 'That is the lady we saw at church.',\n",
       " 'That is the lady we saw at church.',\n",
       " \"I'm here before you, ready for combat,\",\n",
       " 'Well,',\n",
       " 'Oh! no,',\n",
       " \"it's my sister Fair that's gone.\",\n",
       " 'I did not,',\n",
       " 'I forgot.',\n",
       " 'How did you forget?',\n",
       " 'The woman of the house gave me a drink that made me forget.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_quoted_sentences(text):\n",
    "    # 使用正則表達式匹配包含雙引號的句子\n",
    "    quoted_sentences = re.findall(r'\\\"(.*?)\\\"', text)\n",
    "    return quoted_sentences\n",
    "\n",
    "# 讀取文件內容\n",
    "with open(\"./fairy_tales/70.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# 提取帶有雙引號的句子\n",
    "quoted_sentences = extract_quoted_sentences(text)\n",
    "\n",
    "# 輸出提取的句子\n",
    "quoted_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"michellejieli/emotion_text_classifier\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"michellejieli/emotion_text_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"michellejieli/emotion_text_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'neutral', 'score': 0.9748895764350891}]\n",
      "[{'label': 'neutral', 'score': 0.988523542881012}]\n",
      "[{'label': 'neutral', 'score': 0.9891825318336487}]\n",
      "[{'label': 'joy', 'score': 0.9340469837188721}]\n",
      "[{'label': 'neutral', 'score': 0.9755856990814209}]\n",
      "[{'label': 'neutral', 'score': 0.9355772137641907}]\n",
      "[{'label': 'neutral', 'score': 0.9824042916297913}]\n",
      "[{'label': 'neutral', 'score': 0.5549980998039246}]\n",
      "[{'label': 'neutral', 'score': 0.9714521765708923}]\n",
      "[{'label': 'neutral', 'score': 0.9597721099853516}]\n",
      "[{'label': 'neutral', 'score': 0.9831492304801941}]\n",
      "[{'label': 'neutral', 'score': 0.9559614658355713}]\n",
      "[{'label': 'neutral', 'score': 0.9791951179504395}]\n",
      "[{'label': 'surprise', 'score': 0.5589516758918762}]\n",
      "[{'label': 'neutral', 'score': 0.5923449397087097}]\n",
      "[{'label': 'neutral', 'score': 0.9868578910827637}]\n",
      "[{'label': 'neutral', 'score': 0.9787057042121887}]\n",
      "[{'label': 'neutral', 'score': 0.9855454564094543}]\n",
      "[{'label': 'neutral', 'score': 0.9863862991333008}]\n",
      "[{'label': 'neutral', 'score': 0.9244867563247681}]\n",
      "[{'label': 'neutral', 'score': 0.9824788570404053}]\n",
      "[{'label': 'neutral', 'score': 0.9407901167869568}]\n",
      "[{'label': 'neutral', 'score': 0.4133760631084442}]\n",
      "[{'label': 'neutral', 'score': 0.973324179649353}]\n",
      "[{'label': 'neutral', 'score': 0.9609038233757019}]\n",
      "[{'label': 'neutral', 'score': 0.951913595199585}]\n",
      "[{'label': 'neutral', 'score': 0.951913595199585}]\n",
      "[{'label': 'neutral', 'score': 0.9775705337524414}]\n",
      "[{'label': 'neutral', 'score': 0.9855454564094543}]\n",
      "[{'label': 'surprise', 'score': 0.96092289686203}]\n",
      "[{'label': 'sadness', 'score': 0.7996808290481567}]\n",
      "[{'label': 'neutral', 'score': 0.8949363231658936}]\n",
      "[{'label': 'neutral', 'score': 0.7246168851852417}]\n",
      "[{'label': 'surprise', 'score': 0.8541349768638611}]\n",
      "[{'label': 'neutral', 'score': 0.5469584465026855}]\n"
     ]
    }
   ],
   "source": [
    "for sentence in quoted_sentences:\n",
    "    print(classifier(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1d2a9ecc905ef171fa753a7e952cc3d53b061ba87f364110eb501a5ad998ef5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
